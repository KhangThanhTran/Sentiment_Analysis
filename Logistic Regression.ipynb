{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4456dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ReadAllFilesInFolder\").getOrCreate()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "# Th√™m c√°c th∆∞ vi·ªán Spark c·∫ßn thi·∫øt\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1537bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|ESCAPE_GAME : C√ÅI...|  neg|\n",
      "|√çt khi m√¨nh ph√†n_...|  neg|\n",
      "|V·ª´a ƒëi ƒÉn buffet ...|  neg|\n",
      "|Th·ª© nh·∫•t , v·ªÅ m·∫∑t...|  neg|\n",
      "|Th·ª©_hai , v·ªÅ m·∫∑t ...|  neg|\n",
      "|Th·ª©_ba , v·ªÅ ch·∫•t_...|  neg|\n",
      "|T∆∞∆°ng_·ªõt , t∆∞∆°ng ...|  neg|\n",
      "|L√∫c m√¨nh v·ªÅ , th·∫•...|  neg|\n",
      "|H√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|\n",
      "|Ch·ªâ c√≥ chuy·ªán n√†y...|  neg|\n",
      "|R·ªìi ƒëang tung_t·∫©y...|  neg|\n",
      "|R·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|\n",
      "|ƒêang ' n√≥i_chuy·ªán...|  neg|\n",
      "|M√¨nh c≈©ng c√≥ n√≥i ...|  neg|\n",
      "|R·∫•t xin_l·ªói anh s...|  neg|\n",
      "|N·∫øu em kh√¥ng nh·∫ßm...|  neg|\n",
      "|M√¨nh m√† l√† con_tr...|  neg|\n",
      "|M√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|\n",
      "|S·ªë_l√† t√¥i v√† c√°c ...|  neg|\n",
      "|T·∫•t_nhi√™n h·ªôi ch√∫...|  neg|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_neg = spark.read.text(\"D:/BinhLuan/data_train/train/neg\").limit(5000)\n",
    "data_pos = spark.read.text(\"D:/BinhLuan/data_train/train/pos\").limit(5000)\n",
    "\n",
    "data_neg_bage = data_neg.withColumn(\"label\", lit(\"neg\"))\n",
    "data_pos_bage = data_pos.withColumn(\"label\", lit(\"pos\"))\n",
    "\n",
    "data = data_neg_bage.union(data_pos_bage)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac5c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, value: string, label: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fc1ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|summary|               value|label|\n",
      "+-------+--------------------+-----+\n",
      "|  count|               10000|10000|\n",
      "|   mean|                null| null|\n",
      "| stddev|                null| null|\n",
      "|    min|! ! ! S·∫Ω quay l·∫°i...|  neg|\n",
      "|    max|üòë ƒëi·ªÉm tr·ª´ l√† c∆°...|  pos|\n",
      "+-------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec6ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|escape_game : c√°i...|  neg|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|\n",
      "|th·ª© nh·∫•t , v·ªÅ m·∫∑t...|  neg|\n",
      "|th·ª©_hai , v·ªÅ m·∫∑t ...|  neg|\n",
      "|th·ª©_ba , v·ªÅ ch·∫•t_...|  neg|\n",
      "|t∆∞∆°ng_·ªõt , t∆∞∆°ng ...|  neg|\n",
      "|l√∫c m√¨nh v·ªÅ , th·∫•...|  neg|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|\n",
      "|ƒëang ' n√≥i_chuy·ªán...|  neg|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi c·ªôt \"text\" th√†nh ch·ªØ th∆∞·ªùng\n",
    "data = data.select(lower(data.value).alias(\"value\"),data.label)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6b972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|escape_game  c√°i_...|  neg|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    pattern =  r\"[^a-zA-Z0-9_√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫µ·∫∑·∫≥√¢·∫•·∫ß·∫©·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ\\sƒëƒê\\s]+\"\n",
    "    clean_text = re.sub(pattern, \"\", text)\n",
    "    return clean_text\n",
    "\n",
    "remove_special_chars_udf = udf(remove_special_chars, StringType())\n",
    "\n",
    "data = data.withColumn(\"value\", remove_special_chars_udf(\"value\"))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc04100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|escape_game  c√°i_...|  neg|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "\n",
    "# X√≥a kho·∫£ng tr·∫Øng d∆∞ th·ª´a trong c·ªôt \"value\"\n",
    "data = data.withColumn(\"value\", trim(data[\"value\"]))\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c h√†ng r·ªóng\n",
    "data = data.na.drop()\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb57b766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|               value|label|               words|\n",
      "+--------------------+-----+--------------------+\n",
      "|escape_game  c√°i_...|  neg|[escape_game, , c...|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|[√≠t, khi, m√¨nh, p...|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|[v·ª´a, ƒëi, ƒÉn, buf...|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|[th·ª©, nh·∫•t, , v·ªÅ,...|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|[th·ª©_hai, , v·ªÅ, m...|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|[th·ª©_ba, , v·ªÅ, ch...|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|[t∆∞∆°ng_·ªõt, , t∆∞∆°n...|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|[l√∫c, m√¨nh, v·ªÅ, ,...|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|[h√¥m_nay, ƒëi, ƒÉn,...|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|[ch·ªâ, c√≥, chuy·ªán,...|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|[r·ªìi, ƒëang, tung_...|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|[r·ªìi, b·∫°n, √Ω, ch·∫°...|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|[ƒëang, , n√≥i_chuy...|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|[m√¨nh, c≈©ng, c√≥, ...|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|[r·∫•t, xin_l·ªói, an...|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|[n·∫øu, em, kh√¥ng, ...|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|[m√¨nh, m√†, l√†, co...|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|[m√¨nh, th·∫≠t_s·ª±, m...|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|[s·ªë_l√†, t√¥i, v√†, ...|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|[t·∫•t_nhi√™n, h·ªôi, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "\n",
    "#T√°ch c√¢u th√†nh c√°c token (Tokenization) \n",
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "df = tokenizer.transform(data)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a6a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|               value|label|              tokens|\n",
      "+--------------------+-----+--------------------+\n",
      "|escape_game  c√°i_...|  neg|[escape_game, c√°i...|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|[ph√†n_n√†n, ch·∫•t_l...|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|[ƒëi, buffet, t·ªëi,...|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|[m·∫∑t, kh√¥ng_gian,...|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|[th·ª©_hai, m·∫∑t, ph...|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|[th·ª©_ba, ch·∫•t_l∆∞·ª£...|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|[t∆∞∆°ng_·ªõt, t∆∞∆°ng,...|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|[1, tr·ªÖ, miss, th...|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|[h√¥m_nay, ƒëi, b√≤,...|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|[chia_s·∫ª, n√≥ng, t...|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|[tung_t·∫©y, ƒëi, ch...|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|[ch·∫°y, ch·ªó, ghi, ...|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|[n√≥i_chuy·ªán, nh√¢n...|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|[kia, ho√†n_to√†n, ...|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|[xin_l·ªói, securit...|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|[nh·∫ßm, tu·∫•n, nh√¢n...|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|[con_trai, c·ª•c_t√≠...|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|[th·∫≠t_s·ª±, chia, t...|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|[b·∫°n_g√°i, nh√†_h√†n...|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|[t·∫•t_nhi√™n, h·ªôi, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "#Lo·∫°i b·ªè Stop Word\n",
    "#ƒê·ªçc file stop word ti·∫øng vi·ªát c√≥ s·∫µn\n",
    "def read_stopwords(stopword_file):\n",
    "    with open(stopword_file, 'r', encoding='utf-8') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "    return stopwords\n",
    "\n",
    "# lo·∫°i b·ªè stop word d·ª±a tr√™n d·ªØ li·ªáu stop word ti·∫øng vi·ªát ·ªü tr√™n\n",
    "def remove_stopwords_vn(words, stopwords):\n",
    "    from underthesea import word_tokenize\n",
    "    tokens = word_tokenize(words)\n",
    "    return [w for w in tokens if w not in stopwords]\n",
    "\n",
    "# Load stop word file\n",
    "stopword_file = 'vietnamese-stopwords.txt'\n",
    "stopwords = read_stopwords(stopword_file)\n",
    "\n",
    "# Define UDF\n",
    "remove_stopwords_udf = udf(lambda x: remove_stopwords_vn(x, stopwords), ArrayType(StringType()))\n",
    "\n",
    "#X√≥a stop word\n",
    "remover = StopWordsRemover(inputCol='words', outputCol='filtered_tokens', stopWords=stopwords)\n",
    "df1 = remover.transform(df).drop('words')\n",
    "df2 = df1.select('value', 'label', remove_stopwords_udf('value').alias('tokens'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe627217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+-------------+\n",
      "|               value|label|              tokens|label_indexer|\n",
      "+--------------------+-----+--------------------+-------------+\n",
      "|escape_game  c√°i_...|  neg|[escape_game, c√°i...|          0.0|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|[ph√†n_n√†n, ch·∫•t_l...|          0.0|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|[ƒëi, buffet, t·ªëi,...|          0.0|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|[m·∫∑t, kh√¥ng_gian,...|          0.0|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|[th·ª©_hai, m·∫∑t, ph...|          0.0|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|[th·ª©_ba, ch·∫•t_l∆∞·ª£...|          0.0|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|[t∆∞∆°ng_·ªõt, t∆∞∆°ng,...|          0.0|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|[1, tr·ªÖ, miss, th...|          0.0|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|[h√¥m_nay, ƒëi, b√≤,...|          0.0|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|[chia_s·∫ª, n√≥ng, t...|          0.0|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|[tung_t·∫©y, ƒëi, ch...|          0.0|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|[ch·∫°y, ch·ªó, ghi, ...|          0.0|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|[n√≥i_chuy·ªán, nh√¢n...|          0.0|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|[kia, ho√†n_to√†n, ...|          0.0|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|[xin_l·ªói, securit...|          0.0|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|[nh·∫ßm, tu·∫•n, nh√¢n...|          0.0|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|[con_trai, c·ª•c_t√≠...|          0.0|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|[th·∫≠t_s·ª±, chia, t...|          0.0|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|[b·∫°n_g√°i, nh√†_h√†n...|          0.0|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|[t·∫•t_nhi√™n, h·ªôi, ...|          0.0|\n",
      "+--------------------+-----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer,VectorIndexer\n",
    "\n",
    "#G√°n nh√£n cho label\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_indexer\").fit(df2)\n",
    "data_transformed = label_indexer.transform(df2)\n",
    "data_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861f2ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+-------------+--------------------+\n",
      "|               value|label|              tokens|label_indexer|        HTF_features|\n",
      "+--------------------+-----+--------------------+-------------+--------------------+\n",
      "|escape_game  c√°i_...|  neg|[escape_game, c√°i...|          0.0|(262144,[66983,24...|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|[ph√†n_n√†n, ch·∫•t_l...|          0.0|(262144,[158,221,...|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|[ƒëi, buffet, t·ªëi,...|          0.0|(262144,[8195,101...|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|[m·∫∑t, kh√¥ng_gian,...|          0.0|(262144,[14793,15...|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|[th·ª©_hai, m·∫∑t, ph...|          0.0|(262144,[4686,750...|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|[th·ª©_ba, ch·∫•t_l∆∞·ª£...|          0.0|(262144,[402,8195...|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|[t∆∞∆°ng_·ªõt, t∆∞∆°ng,...|          0.0|(262144,[1875,351...|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|[1, tr·ªÖ, miss, th...|          0.0|(262144,[68,11592...|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|[h√¥m_nay, ƒëi, b√≤,...|          0.0|(262144,[1084,235...|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|[chia_s·∫ª, n√≥ng, t...|          0.0|(262144,[725,1252...|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|[tung_t·∫©y, ƒëi, ch...|          0.0|(262144,[1479,125...|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|[ch·∫°y, ch·ªó, ghi, ...|          0.0|(262144,[1926,505...|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|[n√≥i_chuy·ªán, nh√¢n...|          0.0|(262144,[5050,114...|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|[kia, ho√†n_to√†n, ...|          0.0|(262144,[46999,52...|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|[xin_l·ªói, securit...|          0.0|(262144,[10193,34...|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|[nh·∫ßm, tu·∫•n, nh√¢n...|          0.0|(262144,[33233,34...|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|[con_trai, c·ª•c_t√≠...|          0.0|(262144,[23556,56...|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|[th·∫≠t_s·ª±, chia, t...|          0.0|(262144,[699,3821...|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|[b·∫°n_g√°i, nh√†_h√†n...|          0.0|(262144,[2446,120...|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|[t·∫•t_nhi√™n, h·ªôi, ...|          0.0|(262144,[5423,848...|\n",
      "+--------------------+-----+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashing_tf = HashingTF(inputCol=\"tokens\", outputCol=\"HTF_features\")\n",
    "\n",
    "#t√≠nh TF \n",
    "df3 = hashing_tf.transform(data_transformed)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4164be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+-------------+--------------------+--------------------+\n",
      "|               value|label|              tokens|label_indexer|        HTF_features|            features|\n",
      "+--------------------+-----+--------------------+-------------+--------------------+--------------------+\n",
      "|escape_game  c√°i_...|  neg|[escape_game, c√°i...|          0.0|(262144,[66983,24...|(262144,[66983,24...|\n",
      "|√≠t khi m√¨nh ph√†n_...|  neg|[ph√†n_n√†n, ch·∫•t_l...|          0.0|(262144,[158,221,...|(262144,[158,221,...|\n",
      "|v·ª´a ƒëi ƒÉn buffet ...|  neg|[ƒëi, buffet, t·ªëi,...|          0.0|(262144,[8195,101...|(262144,[8195,101...|\n",
      "|th·ª© nh·∫•t  v·ªÅ m·∫∑t ...|  neg|[m·∫∑t, kh√¥ng_gian,...|          0.0|(262144,[14793,15...|(262144,[14793,15...|\n",
      "|th·ª©_hai  v·ªÅ m·∫∑t p...|  neg|[th·ª©_hai, m·∫∑t, ph...|          0.0|(262144,[4686,750...|(262144,[4686,750...|\n",
      "|th·ª©_ba  v·ªÅ ch·∫•t_l...|  neg|[th·ª©_ba, ch·∫•t_l∆∞·ª£...|          0.0|(262144,[402,8195...|(262144,[402,8195...|\n",
      "|t∆∞∆°ng_·ªõt  t∆∞∆°ng c...|  neg|[t∆∞∆°ng_·ªõt, t∆∞∆°ng,...|          0.0|(262144,[1875,351...|(262144,[1875,351...|\n",
      "|l√∫c m√¨nh v·ªÅ  th·∫•y...|  neg|[1, tr·ªÖ, miss, th...|          0.0|(262144,[68,11592...|(262144,[68,11592...|\n",
      "|h√¥m_nay ƒëi ƒÉn b√≤ ...|  neg|[h√¥m_nay, ƒëi, b√≤,...|          0.0|(262144,[1084,235...|(262144,[1084,235...|\n",
      "|ch·ªâ c√≥ chuy·ªán n√†y...|  neg|[chia_s·∫ª, n√≥ng, t...|          0.0|(262144,[725,1252...|(262144,[725,1252...|\n",
      "|r·ªìi ƒëang tung_t·∫©y...|  neg|[tung_t·∫©y, ƒëi, ch...|          0.0|(262144,[1479,125...|(262144,[1479,125...|\n",
      "|r·ªìi b·∫°n √Ω ch·∫°y ra...|  neg|[ch·∫°y, ch·ªó, ghi, ...|          0.0|(262144,[1926,505...|(262144,[1926,505...|\n",
      "|ƒëang  n√≥i_chuy·ªán ...|  neg|[n√≥i_chuy·ªán, nh√¢n...|          0.0|(262144,[5050,114...|(262144,[5050,114...|\n",
      "|m√¨nh c≈©ng c√≥ n√≥i ...|  neg|[kia, ho√†n_to√†n, ...|          0.0|(262144,[46999,52...|(262144,[46999,52...|\n",
      "|r·∫•t xin_l·ªói anh s...|  neg|[xin_l·ªói, securit...|          0.0|(262144,[10193,34...|(262144,[10193,34...|\n",
      "|n·∫øu em kh√¥ng nh·∫ßm...|  neg|[nh·∫ßm, tu·∫•n, nh√¢n...|          0.0|(262144,[33233,34...|(262144,[33233,34...|\n",
      "|m√¨nh m√† l√† con_tr...|  neg|[con_trai, c·ª•c_t√≠...|          0.0|(262144,[23556,56...|(262144,[23556,56...|\n",
      "|m√¨nh th·∫≠t_s·ª± mu·ªën...|  neg|[th·∫≠t_s·ª±, chia, t...|          0.0|(262144,[699,3821...|(262144,[699,3821...|\n",
      "|s·ªë_l√† t√¥i v√† c√°c ...|  neg|[b·∫°n_g√°i, nh√†_h√†n...|          0.0|(262144,[2446,120...|(262144,[2446,120...|\n",
      "|t·∫•t_nhi√™n h·ªôi ch√∫...|  neg|[t·∫•t_nhi√™n, h·ªôi, ...|          0.0|(262144,[5423,848...|(262144,[5423,848...|\n",
      "+--------------------+-----+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"HTF_features\", outputCol=\"features\")\n",
    "\n",
    "#t√≠nh ITF \n",
    "idfModel = idf.fit(df3)\n",
    "                   \n",
    "df4 = idfModel.transform(df3)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f426d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01, featuresCol=\"features\", labelCol=\"label_indexer\", predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# t·∫°o pipeline ƒë·ªÉ th·ª±c hi·ªán c√°c b∆∞·ªõc x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a834f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chia t·∫≠p d·ªØ li·ªáu th√†nh train, test theo t·ª∑ l·ªá 70:30\n",
    "#(train_data, test_data) = data_transformed.randomSplit([0.7, 0.3], seed=12345)\n",
    "#chia t·∫≠p d·ªØ li·ªáu th√†nh train, test theo t·ª∑ l·ªá 80:20\n",
    "(train_data, test_data) = data_transformed.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f80ced15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87afcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "778d6024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.751246\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#t√≠nh to√°n ƒë·ªô ch√≠nh x√°c\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label_indexer\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ad8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----------+\n",
      "|label|label_indexer|prediction|\n",
      "+-----+-------------+----------+\n",
      "|  pos|          1.0|       0.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       0.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       0.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "|  pos|          1.0|       1.0|\n",
      "+-----+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions.label_indexer == 1.0).select('label', 'label_indexer', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa921e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----------+\n",
      "|label|label_indexer|prediction|\n",
      "+-----+-------------+----------+\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       1.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       1.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       1.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       0.0|\n",
      "|  neg|          0.0|       1.0|\n",
      "+-----+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions.label_indexer == 0.0).select('label', 'label_indexer', 'prediction').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
